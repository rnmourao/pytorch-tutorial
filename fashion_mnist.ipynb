{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD\n",
    "from torch.nn import functional as fn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepNet, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.nn_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 10)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.flatten(input)\n",
    "        x = self.nn_stack(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepNet(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (nn_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=200, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = DeepNet().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, dataloader, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # calculate error\n",
    "        pred = model.forward(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            train_loss = loss.item()\n",
    "            current = batch * len(X)\n",
    "            print(f\"loss: {train_loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, dataloader, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "                X = X.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "                # calculate error\n",
    "                pred = model.forward(X)\n",
    "                test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "                correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "loss: 2.320418  [    0/60000]\n",
      "loss: 0.981808  [ 6400/60000]\n",
      "loss: 0.594293  [12800/60000]\n",
      "loss: 0.710337  [19200/60000]\n",
      "loss: 0.593947  [25600/60000]\n",
      "loss: 0.493177  [32000/60000]\n",
      "loss: 0.484941  [38400/60000]\n",
      "loss: 0.639416  [44800/60000]\n",
      "loss: 0.569331  [51200/60000]\n",
      "loss: 0.557674  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.507733 \n",
      "\n",
      "Epoch 1:\n",
      "loss: 0.359407  [    0/60000]\n",
      "loss: 0.448707  [ 6400/60000]\n",
      "loss: 0.326884  [12800/60000]\n",
      "loss: 0.498036  [19200/60000]\n",
      "loss: 0.448423  [25600/60000]\n",
      "loss: 0.444438  [32000/60000]\n",
      "loss: 0.394728  [38400/60000]\n",
      "loss: 0.551251  [44800/60000]\n",
      "loss: 0.483355  [51200/60000]\n",
      "loss: 0.539059  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.447450 \n",
      "\n",
      "Epoch 2:\n",
      "loss: 0.279203  [    0/60000]\n",
      "loss: 0.400369  [ 6400/60000]\n",
      "loss: 0.289571  [12800/60000]\n",
      "loss: 0.426277  [19200/60000]\n",
      "loss: 0.408787  [25600/60000]\n",
      "loss: 0.410262  [32000/60000]\n",
      "loss: 0.349683  [38400/60000]\n",
      "loss: 0.525344  [44800/60000]\n",
      "loss: 0.447980  [51200/60000]\n",
      "loss: 0.494188  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.430419 \n",
      "\n",
      "Epoch 3:\n",
      "loss: 0.262196  [    0/60000]\n",
      "loss: 0.367049  [ 6400/60000]\n",
      "loss: 0.268699  [12800/60000]\n",
      "loss: 0.372691  [19200/60000]\n",
      "loss: 0.362837  [25600/60000]\n",
      "loss: 0.393575  [32000/60000]\n",
      "loss: 0.305627  [38400/60000]\n",
      "loss: 0.500603  [44800/60000]\n",
      "loss: 0.416104  [51200/60000]\n",
      "loss: 0.458323  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.417800 \n",
      "\n",
      "Epoch 4:\n",
      "loss: 0.243968  [    0/60000]\n",
      "loss: 0.336774  [ 6400/60000]\n",
      "loss: 0.247273  [12800/60000]\n",
      "loss: 0.319837  [19200/60000]\n",
      "loss: 0.331635  [25600/60000]\n",
      "loss: 0.376064  [32000/60000]\n",
      "loss: 0.283625  [38400/60000]\n",
      "loss: 0.469601  [44800/60000]\n",
      "loss: 0.399004  [51200/60000]\n",
      "loss: 0.438975  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.396858 \n",
      "\n",
      "Epoch 5:\n",
      "loss: 0.234907  [    0/60000]\n",
      "loss: 0.305619  [ 6400/60000]\n",
      "loss: 0.224734  [12800/60000]\n",
      "loss: 0.284555  [19200/60000]\n",
      "loss: 0.332611  [25600/60000]\n",
      "loss: 0.355324  [32000/60000]\n",
      "loss: 0.259428  [38400/60000]\n",
      "loss: 0.447583  [44800/60000]\n",
      "loss: 0.362922  [51200/60000]\n",
      "loss: 0.399492  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.374782 \n",
      "\n",
      "Epoch 6:\n",
      "loss: 0.216026  [    0/60000]\n",
      "loss: 0.283604  [ 6400/60000]\n",
      "loss: 0.216267  [12800/60000]\n",
      "loss: 0.261523  [19200/60000]\n",
      "loss: 0.322117  [25600/60000]\n",
      "loss: 0.345000  [32000/60000]\n",
      "loss: 0.237145  [38400/60000]\n",
      "loss: 0.419820  [44800/60000]\n",
      "loss: 0.343652  [51200/60000]\n",
      "loss: 0.392339  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.364334 \n",
      "\n",
      "Epoch 7:\n",
      "loss: 0.197289  [    0/60000]\n",
      "loss: 0.276666  [ 6400/60000]\n",
      "loss: 0.212467  [12800/60000]\n",
      "loss: 0.247259  [19200/60000]\n",
      "loss: 0.337508  [25600/60000]\n",
      "loss: 0.335524  [32000/60000]\n",
      "loss: 0.243149  [38400/60000]\n",
      "loss: 0.396079  [44800/60000]\n",
      "loss: 0.328676  [51200/60000]\n",
      "loss: 0.345789  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.352071 \n",
      "\n",
      "Epoch 8:\n",
      "loss: 0.180139  [    0/60000]\n",
      "loss: 0.269894  [ 6400/60000]\n",
      "loss: 0.211757  [12800/60000]\n",
      "loss: 0.231575  [19200/60000]\n",
      "loss: 0.328056  [25600/60000]\n",
      "loss: 0.315579  [32000/60000]\n",
      "loss: 0.250726  [38400/60000]\n",
      "loss: 0.387513  [44800/60000]\n",
      "loss: 0.299819  [51200/60000]\n",
      "loss: 0.350180  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.349345 \n",
      "\n",
      "Epoch 9:\n",
      "loss: 0.178259  [    0/60000]\n",
      "loss: 0.258574  [ 6400/60000]\n",
      "loss: 0.207726  [12800/60000]\n",
      "loss: 0.224440  [19200/60000]\n",
      "loss: 0.327256  [25600/60000]\n",
      "loss: 0.307738  [32000/60000]\n",
      "loss: 0.232637  [38400/60000]\n",
      "loss: 0.349872  [44800/60000]\n",
      "loss: 0.276091  [51200/60000]\n",
      "loss: 0.324386  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.350713 \n",
      "\n",
      "Epoch 10:\n",
      "loss: 0.174719  [    0/60000]\n",
      "loss: 0.251951  [ 6400/60000]\n",
      "loss: 0.211310  [12800/60000]\n",
      "loss: 0.214511  [19200/60000]\n",
      "loss: 0.318985  [25600/60000]\n",
      "loss: 0.272049  [32000/60000]\n",
      "loss: 0.215238  [38400/60000]\n",
      "loss: 0.350844  [44800/60000]\n",
      "loss: 0.290495  [51200/60000]\n",
      "loss: 0.317622  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.347178 \n",
      "\n",
      "Epoch 11:\n",
      "loss: 0.167509  [    0/60000]\n",
      "loss: 0.235578  [ 6400/60000]\n",
      "loss: 0.210929  [12800/60000]\n",
      "loss: 0.205984  [19200/60000]\n",
      "loss: 0.290186  [25600/60000]\n",
      "loss: 0.265335  [32000/60000]\n",
      "loss: 0.207037  [38400/60000]\n",
      "loss: 0.337143  [44800/60000]\n",
      "loss: 0.282964  [51200/60000]\n",
      "loss: 0.300857  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.347615 \n",
      "\n",
      "Epoch 12:\n",
      "loss: 0.170605  [    0/60000]\n",
      "loss: 0.227061  [ 6400/60000]\n",
      "loss: 0.209114  [12800/60000]\n",
      "loss: 0.194191  [19200/60000]\n",
      "loss: 0.297234  [25600/60000]\n",
      "loss: 0.253573  [32000/60000]\n",
      "loss: 0.199726  [38400/60000]\n",
      "loss: 0.314451  [44800/60000]\n",
      "loss: 0.247953  [51200/60000]\n",
      "loss: 0.279403  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.346756 \n",
      "\n",
      "Epoch 13:\n",
      "loss: 0.174010  [    0/60000]\n",
      "loss: 0.203493  [ 6400/60000]\n",
      "loss: 0.218959  [12800/60000]\n",
      "loss: 0.180128  [19200/60000]\n",
      "loss: 0.291731  [25600/60000]\n",
      "loss: 0.221226  [32000/60000]\n",
      "loss: 0.187760  [38400/60000]\n",
      "loss: 0.313509  [44800/60000]\n",
      "loss: 0.240854  [51200/60000]\n",
      "loss: 0.283088  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.344054 \n",
      "\n",
      "Epoch 14:\n",
      "loss: 0.157085  [    0/60000]\n",
      "loss: 0.192308  [ 6400/60000]\n",
      "loss: 0.215145  [12800/60000]\n",
      "loss: 0.172973  [19200/60000]\n",
      "loss: 0.293470  [25600/60000]\n",
      "loss: 0.229097  [32000/60000]\n",
      "loss: 0.187972  [38400/60000]\n",
      "loss: 0.308560  [44800/60000]\n",
      "loss: 0.239351  [51200/60000]\n",
      "loss: 0.255422  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.344497 \n",
      "\n",
      "Epoch 15:\n",
      "loss: 0.162685  [    0/60000]\n",
      "loss: 0.189108  [ 6400/60000]\n",
      "loss: 0.224076  [12800/60000]\n",
      "loss: 0.164782  [19200/60000]\n",
      "loss: 0.276186  [25600/60000]\n",
      "loss: 0.225884  [32000/60000]\n",
      "loss: 0.191517  [38400/60000]\n",
      "loss: 0.302301  [44800/60000]\n",
      "loss: 0.233563  [51200/60000]\n",
      "loss: 0.211481  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.341524 \n",
      "\n",
      "Epoch 16:\n",
      "loss: 0.157962  [    0/60000]\n",
      "loss: 0.175435  [ 6400/60000]\n",
      "loss: 0.221082  [12800/60000]\n",
      "loss: 0.146855  [19200/60000]\n",
      "loss: 0.296956  [25600/60000]\n",
      "loss: 0.210482  [32000/60000]\n",
      "loss: 0.184513  [38400/60000]\n",
      "loss: 0.289441  [44800/60000]\n",
      "loss: 0.221683  [51200/60000]\n",
      "loss: 0.182787  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.346417 \n",
      "\n",
      "Epoch 17:\n",
      "loss: 0.158167  [    0/60000]\n",
      "loss: 0.178388  [ 6400/60000]\n",
      "loss: 0.210658  [12800/60000]\n",
      "loss: 0.139881  [19200/60000]\n",
      "loss: 0.288646  [25600/60000]\n",
      "loss: 0.203864  [32000/60000]\n",
      "loss: 0.190422  [38400/60000]\n",
      "loss: 0.284440  [44800/60000]\n",
      "loss: 0.209567  [51200/60000]\n",
      "loss: 0.184245  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.347127 \n",
      "\n",
      "Epoch 18:\n",
      "loss: 0.142689  [    0/60000]\n",
      "loss: 0.158642  [ 6400/60000]\n",
      "loss: 0.202464  [12800/60000]\n",
      "loss: 0.128398  [19200/60000]\n",
      "loss: 0.278484  [25600/60000]\n",
      "loss: 0.208992  [32000/60000]\n",
      "loss: 0.183164  [38400/60000]\n",
      "loss: 0.266439  [44800/60000]\n",
      "loss: 0.206067  [51200/60000]\n",
      "loss: 0.157802  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.348082 \n",
      "\n",
      "Epoch 19:\n",
      "loss: 0.149014  [    0/60000]\n",
      "loss: 0.149821  [ 6400/60000]\n",
      "loss: 0.209641  [12800/60000]\n",
      "loss: 0.126312  [19200/60000]\n",
      "loss: 0.311936  [25600/60000]\n",
      "loss: 0.219986  [32000/60000]\n",
      "loss: 0.171672  [38400/60000]\n",
      "loss: 0.240667  [44800/60000]\n",
      "loss: 0.212621  [51200/60000]\n",
      "loss: 0.156385  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.343386 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = range(20)\n",
    "\n",
    "for epoch in epochs:\n",
    "    print(f\"Epoch {epoch}:\")\n",
    "    train(model, device, train_dataloader, loss_fn, optimizer)\n",
    "    test(model, device, test_dataloader, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e53795efdf6d2a32782100f016dd1331ebd026b741e98386f1de6175d96a678e"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('venv': virtualenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
